{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnSl67vA7Jmo",
        "outputId": "08bfada2-37f3-409a-937e-f6d40d445980"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "qe4tAcff9iTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_json(\"hf://datasets/RafaelMPereira/HealthCareMagic-100k-Chat-Format-en/HealthCareMagic-100k-en.jsonl\", lines=True)\n",
        "\n",
        "print(dataset.head())"
      ],
      "metadata": {
        "id": "c5BHKfHv_90C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE2rz0Uk6GU-",
        "outputId": "885d63aa-4e74-4c9c-d3e6-6ecb075de58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (112165, 384)\n",
            "First embedding: [ 7.22346604e-02 -1.50009736e-01 -2.52121920e-03 -2.54227556e-02\n",
            "  5.86471297e-02 -2.34740265e-02  4.12268043e-02  4.85854736e-03\n",
            "  8.50420892e-02 -7.87990168e-02 -3.20293382e-02  3.83367091e-02\n",
            "  5.80538735e-02 -1.31933275e-03 -5.30180102e-03  1.34680280e-03\n",
            "  3.02392077e-02  3.10588721e-02 -1.40234707e-02  1.07843913e-01\n",
            " -5.92860840e-02  1.34643447e-02 -3.55862416e-02  1.25084504e-01\n",
            " -5.75057194e-02  1.04742840e-01  1.07758544e-01 -7.20307007e-02\n",
            " -4.73776087e-02 -6.48988262e-02  1.27694579e-02  3.61588709e-02\n",
            " -6.35851687e-03 -5.29292710e-02  5.65906847e-03  3.10765710e-02\n",
            " -4.20723669e-02  1.93113629e-02 -3.10883988e-02 -8.42939243e-02\n",
            "  1.58446394e-02  1.47263985e-02  7.15667848e-03 -3.44332345e-02\n",
            "  1.13743600e-02  5.87707683e-02 -1.63660925e-02 -3.91083118e-03\n",
            "  5.52701242e-02  6.35994822e-02  4.60485928e-04 -3.23220082e-02\n",
            "  5.76261021e-02 -2.86581516e-02  3.75659554e-03  6.05800888e-03\n",
            "  3.84877287e-02 -5.97246699e-02 -2.18706932e-02  2.37092245e-02\n",
            "  1.34195806e-02 -4.83222585e-03  3.87545042e-02 -3.33917849e-02\n",
            "  8.38320795e-03  4.69035394e-02  4.47505750e-02 -4.82567921e-05\n",
            "  8.49622935e-02 -2.60888916e-02 -2.84812655e-02 -8.43592808e-02\n",
            " -2.70276833e-02 -9.17270035e-03  1.23143299e-02 -1.28160603e-02\n",
            "  6.33217171e-02 -7.27256984e-02  7.65513908e-03  5.73497564e-02\n",
            " -3.48529741e-02  1.10928565e-01  2.76320875e-02 -1.12654092e-02\n",
            "  4.69176652e-04 -1.14837354e-02 -2.64828035e-04  1.49983078e-01\n",
            " -4.03030179e-02  3.36433062e-03  6.38751239e-02  1.70375519e-02\n",
            " -4.84411977e-02 -3.75715420e-02  1.29075691e-01 -1.20154573e-02\n",
            " -8.64675567e-02 -2.78034993e-02 -3.12725902e-02 -1.44207189e-02\n",
            "  4.80662137e-02  6.86182058e-04  7.44760185e-02  2.41325926e-02\n",
            " -3.56118567e-02  1.32219875e-02  9.63678434e-02 -6.19169921e-02\n",
            " -5.16571850e-02 -5.64994551e-02 -5.48416702e-03  2.28982177e-02\n",
            "  1.44929094e-02  1.70838758e-02 -6.36710227e-02  3.20158340e-02\n",
            "  2.99578602e-03  2.74122804e-02 -1.48719354e-02  6.39267564e-02\n",
            "  4.42572450e-03  9.16053634e-03  9.83547606e-03 -4.89466339e-02\n",
            " -5.27191274e-02  6.53472263e-03 -7.66500235e-02  1.95072167e-33\n",
            "  1.58607098e-03  2.76807584e-02  4.87223566e-02 -3.85554694e-03\n",
            "  2.50378288e-02 -7.56284669e-02 -4.19281982e-02  5.68106119e-03\n",
            "  3.29091698e-02 -4.09311391e-02  3.02918479e-02 -3.54150273e-02\n",
            "  1.77211370e-02 -5.01819551e-02 -9.40283760e-02 -4.91060726e-02\n",
            "  7.69336056e-03  1.80222802e-02  2.61700004e-02  1.06499456e-02\n",
            " -1.95967369e-02 -8.06988031e-03 -8.46079066e-02  3.67043018e-02\n",
            " -3.71345282e-02  4.01332602e-02 -7.10985139e-02  1.14712883e-02\n",
            " -4.81030419e-02 -7.10383384e-03  3.08719147e-02 -1.76772811e-02\n",
            " -6.27623647e-02  1.07403090e-02 -5.50060160e-02 -1.29790016e-04\n",
            " -5.93481632e-03  4.56044376e-02  1.64456778e-05 -8.14517774e-03\n",
            " -9.50189587e-03  5.20439856e-02 -6.49906173e-02  8.24249014e-02\n",
            "  3.77187543e-02 -1.41525771e-02 -3.29591855e-02  5.90499751e-02\n",
            " -1.69405174e-02  2.55760010e-02  1.88665204e-02 -3.19999568e-02\n",
            " -1.45494612e-02 -7.23957270e-02  1.31854387e-02  1.09562802e-03\n",
            "  1.99609641e-02 -2.55479407e-03  3.51104625e-02  7.53246099e-02\n",
            "  3.34363505e-02  1.03743441e-01 -4.88081500e-02 -1.08720243e-01\n",
            "  3.87956086e-03 -1.59099102e-02 -4.07838961e-04 -1.77897289e-02\n",
            " -6.30144309e-03 -1.00723710e-02 -5.06911278e-02  7.82657191e-02\n",
            "  7.96626974e-03  1.38562456e-01  8.62430483e-02 -1.46036586e-02\n",
            " -9.57559943e-02 -4.97609451e-02 -7.42995068e-02 -6.58366159e-02\n",
            "  7.17906887e-03  6.88399421e-03  1.32905871e-01  4.51767724e-03\n",
            "  2.61602122e-02  4.95774485e-02 -3.37750986e-02  1.21398503e-02\n",
            " -1.86330140e-01  5.94999753e-02  7.82177895e-02  4.33571488e-02\n",
            " -1.15927243e-04  2.52170768e-02 -3.54770534e-02 -2.91476424e-33\n",
            " -4.15947065e-02 -3.90424393e-02 -5.00490069e-02  1.61614381e-02\n",
            " -1.08773392e-02 -4.44703326e-02  1.29479747e-02 -3.59289423e-02\n",
            " -8.92120376e-02 -1.07016362e-01  6.48463294e-02  2.31284779e-02\n",
            "  9.54079442e-04  8.52915049e-02  6.07641041e-02  5.84009811e-02\n",
            "  6.98530450e-02  6.15832908e-03 -4.13095541e-02  1.70918200e-02\n",
            "  2.16241758e-02 -2.26163194e-02  3.00831497e-02 -4.72050831e-02\n",
            " -1.10881040e-02  4.79447357e-02  9.26588401e-02  1.39403492e-02\n",
            "  6.10272810e-02  7.57956952e-02  2.64734179e-02  9.70470309e-02\n",
            " -1.75023563e-02 -6.30913582e-03 -1.86085030e-02  1.21342409e-02\n",
            " -8.86730030e-02 -2.33853012e-02 -7.25895539e-02 -4.42773029e-02\n",
            " -5.71298823e-02  9.44450945e-02  5.12440354e-02 -5.65268174e-02\n",
            " -6.31715655e-02 -2.34528184e-02  1.40630277e-02 -2.84528341e-02\n",
            " -3.60945202e-02  1.77966822e-02 -4.05119173e-02  5.04502207e-02\n",
            "  5.51638333e-03 -3.49369855e-03  7.98389167e-02  2.98889000e-02\n",
            " -4.06103507e-02 -7.69447982e-02  3.51185612e-02 -9.72651616e-02\n",
            " -4.82224934e-02  3.55482213e-02 -6.11783527e-02 -6.34274855e-02\n",
            "  6.17236234e-02  2.87518110e-02  1.19372746e-02 -2.09871661e-02\n",
            "  6.83066621e-02  3.03055719e-02 -4.78254594e-02 -8.36580060e-03\n",
            " -3.19308303e-02 -7.10092299e-03 -3.83267887e-02  1.25075370e-01\n",
            "  7.58732557e-02  1.00898920e-02  7.41327032e-02 -8.46266001e-02\n",
            " -2.75497437e-02  4.54176776e-02  1.08930722e-01 -5.49840927e-02\n",
            " -5.88789955e-02 -4.24050055e-02 -4.65407819e-02 -2.56863032e-02\n",
            "  6.73992792e-03  3.66282575e-02  5.23474030e-02  6.57224562e-04\n",
            " -3.42770927e-02  2.51895599e-02  7.45267570e-02 -5.34568478e-08\n",
            " -7.22185299e-02 -8.25062469e-02 -5.25304936e-02  5.75884134e-02\n",
            " -4.51425761e-02  1.27942655e-02  7.54382648e-03 -1.93137862e-02\n",
            " -5.95801510e-02  7.93572702e-03 -6.57492802e-02 -5.19614927e-02\n",
            "  3.77097763e-02 -2.02101264e-02 -1.71341132e-02  6.32118657e-02\n",
            " -1.37489103e-02  8.70180503e-02 -1.22582121e-02 -2.52931751e-03\n",
            "  2.10181661e-02 -2.11756416e-02 -7.47860819e-02 -3.21070626e-02\n",
            "  7.28708133e-02  1.49955107e-02  7.81507231e-03  2.81648822e-02\n",
            "  1.70467868e-02 -1.05333582e-01  3.33962068e-02  1.87195931e-03\n",
            " -3.85559238e-02 -6.63382113e-02 -1.01965323e-01 -3.79026458e-02\n",
            "  3.25636379e-02 -7.02242274e-03  5.51083609e-02  3.46104540e-02\n",
            " -3.97621505e-02 -3.45126204e-02 -5.08700088e-02 -3.93896550e-02\n",
            " -8.04310292e-03 -7.67377466e-02  7.93927833e-02  1.10027045e-02\n",
            "  4.36947085e-02 -2.23886911e-02  3.68514769e-02 -4.93913610e-03\n",
            "  1.18510909e-01  9.29122716e-02  3.31493877e-02  6.38593733e-02\n",
            " -2.69517954e-02  1.80303573e-03 -5.93513111e-03 -3.38439718e-02\n",
            " -5.52376211e-02 -3.65734771e-02 -1.04995213e-01 -7.19812419e-03]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "def create_embeddings(dataset):\n",
        "    # Generate embeddings for the 'text'\n",
        "    texts = dataset['text'].tolist()\n",
        "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "embeddings = create_embeddings(dataset)\n",
        "\n",
        "\n",
        "embeddings_np = embeddings.cpu().numpy()\n",
        "\n",
        "\n",
        "# Print shape and a sample embedding\n",
        "print(\"Embeddings shape:\", embeddings_np.shape)\n",
        "print(\"First embedding:\", embeddings_np[0])\n"
      ]
    }
  ]
}